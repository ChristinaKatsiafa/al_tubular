{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "\n",
    "# Add the local directory to the Python path\n",
    "sys.path.append('/workspaces/tubular/')\n",
    "\n",
    "import datetime\n",
    "import warnings\n",
    "import zoneinfo\n",
    "from typing import TYPE_CHECKING\n",
    "\n",
    "import narwhals as nw\n",
    "import narwhals.selectors as ncs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tubular.base import BaseTransformer\n",
    "from tubular.mixins import DropOriginalMixin, NewColumnNameMixin, TwoColumnMixin\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from narhwals.typing import FrameT\n",
    "\n",
    "TIME_UNITS = [\"us\", \"ns\", \"ms\"]\n",
    "TIME_ZONES = zoneinfo.available_timezones().union({None})\n",
    "\n",
    "DATETIME_VARIANTS = [\n",
    "    nw.Datetime(time_unit=time_unit, time_zone=time_zone)\n",
    "    for time_unit in TIME_UNITS\n",
    "    for time_zone in TIME_ZONES\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import tests.utils as u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_date_diff_different_dtypes_and_nans(library=\"pandas\"):\n",
    "    \"\"\"Dataframe with different datetime formats with nans in the data\"\"\"\n",
    "\n",
    "    df_dict = {\n",
    "        \"date_col_1\": [\n",
    "            None,\n",
    "            datetime.date(2000, 3, 19),\n",
    "            datetime.date(2018, 11, 10),\n",
    "            datetime.date(2018, 10, 10),\n",
    "            datetime.date(2018, 10, 10),\n",
    "            datetime.date(2018, 10, 10),\n",
    "            datetime.date(2018, 12, 10),\n",
    "            datetime.date(\n",
    "                1985,\n",
    "                7,\n",
    "                23,\n",
    "            ),\n",
    "        ],\n",
    "        \"date_col_2\": [\n",
    "            datetime.date(2020, 5, 1),\n",
    "            datetime.date(2019, 12, 25),\n",
    "            datetime.date(2018, 11, 10),\n",
    "            datetime.date(2018, 11, 10),\n",
    "            datetime.date(2018, 9, 10),\n",
    "            datetime.date(2015, 11, 10),\n",
    "            datetime.date(2015, 11, 10),\n",
    "            datetime.date(2015, 7, 23),\n",
    "        ],\n",
    "        \"datetime_col_1\": [\n",
    "            datetime.datetime(1993, 9, 27, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2000, 3, 19, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 11, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 10, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 10, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 10, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 12, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(\n",
    "                1985,\n",
    "                7,\n",
    "                23,\n",
    "                tzinfo=datetime.timezone.utc,\n",
    "            ),\n",
    "        ],\n",
    "        \"datetime_col_2\": [\n",
    "            None,\n",
    "            datetime.datetime(2019, 12, 25, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 11, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 11, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2018, 9, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2015, 11, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2015, 11, 10, tzinfo=datetime.timezone.utc),\n",
    "            datetime.datetime(2015, 7, 23, tzinfo=datetime.timezone.utc),\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return u.dataframe_init_dispatch(df_dict, library=library)\n",
    "\n",
    "def expected_date_diff_df_2(library=\"pandas\"):\n",
    "    \"\"\"Expected output for test_expected_output_drop_cols_true.\"\"\"\n",
    "\n",
    "    df_dict = {\n",
    "        \"c\": [\n",
    "            None,\n",
    "            19,\n",
    "            0,\n",
    "            0,\n",
    "            0,\n",
    "            -2,\n",
    "            -3,\n",
    "            30,\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    return u.dataframe_init_dispatch(df_dict, library=library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pol = create_date_diff_different_dtypes_and_nans(library=\"polars\")\n",
    "df_pd = create_date_diff_different_dtypes_and_nans(library=\"pandas\")\n",
    "df_exp_pol = expected_date_diff_df_2(library=\"polars\")\n",
    "df_exp_pd = expected_date_diff_df_2(library=\"pandas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Traceback (most recent call last):\n",
       "  File \"/home/vscode/.vscode-remote/extensions/ms-python.python-2025.2.0-linux-x64/python_files/python_server.py\", line 133, in exec_user_input\n",
       "    retval = callable_(user_input, user_globals)\n",
       "  File \"<string>\", line 13\n",
       "    X = X.with_columns(\n",
       "    ^\n",
       "SyntaxError: invalid syntax\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def fun(\n",
    "        X,\n",
    "        columns : list,\n",
    "        missing_replacement : str,\n",
    "        new_column_name : str):\n",
    "    X = nw.from_native(X)\n",
    "    \n",
    "    X = X.with_columns(\n",
    "        (nw.col(columns[0]).cast(nw.Date).dt.year().cast(nw.Int64) * 10000 +\n",
    "        nw.col(columns[0]).cast(nw.Date).dt.month().cast(nw.Int64) * 100 +\n",
    "        nw.col(columns[0]).cast(nw.Date).dt.day().cast(nw.Int64)).alias(\"col0\")\n",
    "    )\n",
    "    X = X.with_columns(\n",
    "        (nw.col(columns[1]).cast(nw.Date).dt.year().cast(nw.Int64) * 10000 +\n",
    "        nw.col(columns[1]).cast(nw.Date).dt.month().cast(nw.Int64) * 100 +\n",
    "        nw.col(columns[1]).cast(nw.Date).dt.day().cast(nw.Int64)).alias(\"col1\")\n",
    "    )\n",
    "\n",
    "    X = X.with_columns(\n",
    "        nw.when(nw.col(\"col1\") < nw.col('col0'))\n",
    "        .then(((nw.col('col0')-nw.col('col1'))//10000)*(-1))\n",
    "        .otherwise((nw.col('col1')-nw.col('col0'))//10000)\n",
    "        .cast(nw.Int64)\n",
    "        .alias(new_column_name)\n",
    "    )\n",
    "    \n",
    "    if missing_replacement is not None:\n",
    "        X = X.with_columns(\n",
    "            nw.when(\n",
    "                (nw.col(columns[0]).is_null())\n",
    "                or (nw.col(columns[1]).is_null())\n",
    "            ).then(\n",
    "                missing_replacement\n",
    "            ).otherwise(\n",
    "                nw.col(new_column_name)\n",
    "            ).cast(nw.Int64).alias(new_column_name)\n",
    "        )\n",
    "\n",
    "    return (X.drop([\"col0\",\"col1\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   date_col_1 date_col_2  ...            datetime_col_2   NEW\n",
       "0        <NA> 2020-05-01  ...                       NaT  <NA>\n",
       "1  2000-03-19 2019-12-25  ... 2019-12-25 00:00:00+00:00     0\n",
       "2  2018-11-10 2018-11-10  ... 2018-11-10 00:00:00+00:00     0\n",
       "3  2018-10-10 2018-11-10  ... 2018-11-10 00:00:00+00:00     0\n",
       "4  2018-10-10 2018-09-10  ... 2018-09-10 00:00:00+00:00     0\n",
       "5  2018-10-10 2015-11-10  ... 2015-11-10 00:00:00+00:00     0\n",
       "6  2018-12-10 2015-11-10  ... 2015-11-10 00:00:00+00:00     0\n",
       "7  1985-07-23 2015-07-23  ... 2015-07-23 00:00:00+00:00     0\n",
       "\n",
       "[8 rows x 5 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fun(X=df_pd,columns=[\"date_col_1\",\"date_col_1\"],missing_replacement=None,new_column_name='NEW').to_native()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   date_col_1 date_col_2  ...            datetime_col_2   NEW\n",
       "0        <NA> 2020-05-01  ...                       NaT  <NA>\n",
       "1  2000-03-19 2019-12-25  ... 2019-12-25 00:00:00+00:00     0\n",
       "2  2018-11-10 2018-11-10  ... 2018-11-10 00:00:00+00:00     0\n",
       "3  2018-10-10 2018-11-10  ... 2018-11-10 00:00:00+00:00     0\n",
       "4  2018-10-10 2018-09-10  ... 2018-09-10 00:00:00+00:00     0\n",
       "5  2018-10-10 2015-11-10  ... 2015-11-10 00:00:00+00:00     0\n",
       "6  2018-12-10 2015-11-10  ... 2015-11-10 00:00:00+00:00     0\n",
       "7  1985-07-23 2015-07-23  ... 2015-07-23 00:00:00+00:00     0\n",
       "\n",
       "[8 rows x 5 columns]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fun(X=df_pd,columns=[\"date_col_1\",\"date_col_1\"],missing_replacement=None,new_column_name='NEW').to_native()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(df_pd)==pd.core.frame.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
